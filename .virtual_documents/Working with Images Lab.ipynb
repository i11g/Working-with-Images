import numpy as np
import os
import matplotlib.pyplot as plt

import pandas as pd
from collections import Counter
from PIL import Image

















os.listdir("data/blackfoot-cat")


os.listdir("data/chinese-mountain-cat")


os.listdir("data/domestic-cat")


os.listdir("data/jungle-cat")


os.listdir("data/european-wildcat")


os.listdir("data/sand-cat")


os.listdir("data/african-wildcat")





files1 = os.listdir("data/african-wildcat")
files2 = os.listdir("data/blackfoot-cat")
files3 = os.listdir("data/chinese-mountain-cat")
files4 = os.listdir("data/domestic-cat")
files5 = os.listdir("data/european-wildcat")
files6 = os.listdir("data/jungle-cat")
files7 = os.listdir("data/sand-cat")
cat_files = files1 + files2 + files3 + files4 + files5 + files6 + files7


# Supported image extensions
IMAGE_EXTENSIONS = ('.jpg', '.jpeg', '.png')

# Folders to scan
folders = [
    "data/african-wildcat",
    "data/blackfoot-cat",
    "data/sand-cat",
    "data/chinese-mountain-cat",
    "data/domestic-cat",
    "data/european-wildcat",
    "data/jungle-cat"
]

# Step 1: Collect image paths and sizes
image_data = []
for folder in folders:
    for file in os.listdir(folder):
        full_path = os.path.join(folder, file)
        if os.path.isfile(full_path) and file.lower().endswith(IMAGE_EXTENSIONS):
            try:
                with Image.open(full_path) as img:
                    width, height = img.size
                    image_data.append((full_path, width, height))
            except Exception as e:
                print(f"Error reading {full_path}: {e}")

# Step 2: Create DataFrame
df = pd.DataFrame(image_data, columns=["path", "width", "height"])

# Step 3: Count most common sizes
size_counts = Counter([(w, h) for _, w, h in image_data])
most_common = size_counts.most_common()

print("üìè Most common image sizes (width x height):")
for size, count in most_common[:10]:  # show top 10
    print(f"{size[0]} x {size[1]} - {count} images")

# Step 4: Average size
if not df.empty:
    avg_width = df["width"].mean()
    avg_height = df["height"].mean()
    print(f"\nüìä Average size: {avg_width:.1f} x {avg_height:.1f} pixels")


# Step 1: Compute area and size
df["area"] = df["width"] * df["height"]
df["size"] = list(zip(df["width"], df["height"]))

# Step 2: Group by size and count
size_counts = df.groupby("size").agg(
    count=("size", "count"),
    width=("width", "first"),
    height=("height", "first"),
    area=("area", "first")
).reset_index(drop=True)

# Step 3: IQR outlier detection function
def detect_outliers(series):
    Q1 = series.quantile(0.25)
    Q3 = series.quantile(0.75)
    IQR = Q3 - Q1
    return (series < Q1 - 1.5 * IQR) | (series > Q3 + 1.5 * IQR)

# Step 4: Apply IQR on width & height
size_counts["outlier_width"] = detect_outliers(size_counts["width"])
size_counts["outlier_height"] = detect_outliers(size_counts["height"])
size_counts["is_outlier"] = size_counts["outlier_width"] | size_counts["outlier_height"]

# Step 5: Filter to only outliers with high counts
threshold = 3
filtered_outliers = size_counts[(size_counts["is_outlier"]) & (size_counts["count"] >= threshold)]

# Step 6: Show outlier size summaries
print(f"\nüîç Outlier sizes that appear at least {threshold} times:")
for _, row in filtered_outliers.iterrows():
    print(f"{row['width']} x {row['height']} - {row['count']} images")

# Step 7: Get actual image paths from df
outlier_sizes = set(zip(filtered_outliers["width"], filtered_outliers["height"]))
outlier_df = df[df["size"].isin(outlier_sizes)]

print(f"\nüì∏ Total outlier images after filtering: {len(outlier_df)}")
print(outlier_df[["path", "width", "height"]].to_string(index=False))






















































